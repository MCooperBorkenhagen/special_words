# The Words Included in Instructional Resources
One possible source of meaningful variability has to do with the words included in instruction: Do instructional resources agree about which words are important in early vocabulary acquisition? If different resources agree about the words to be prioritized for memorization^[See resource descriptions for a full account of the teaching methods associated with each approach. Nonetheless, each approach involves some amount of word memorization.], then students experiencing these programs would have similar experiences - at least in terms of the words taught. Alternatively, if resources differ in their contents, it would suggest that the students that learn different programs have different experiences. Variability of this kind is important because it suggests different conceptualizations of what is important in early reading development, leaving aside issues of the relative efficacy of one approach versus another.
 
# The degree of overlap of words across sources
```{r intersect_sources, include=FALSE}

intersect_words_ = wcbc %>% 
  filter(word %in% intersect_words) %>% 
  select(word, wcbc_rank) %>% 
  arrange(-desc(wcbc_rank)) %>% 
  mutate(final = str_c(word, ' (*', wcbc_rank, '*)')) %>% 
  select(final) %>% 
  pull(final)

intersect_words_ = c(intersect_words_, c('', ''))

intersect_words_table = matrix(intersect_words_, nrow = 4, ncol = 7)

```

If there is a high degree of consensus about the sight word construct, then sources associated with the construct should share a set of common words across them (holding aside the issue of sources different quantities of words across sources). Across the six instructional sources included for analysis here, only ```r length(intersect_words)``` of all unique words are shared across all sources (```r round(length(intersect_words)/length(unique(all_lists$word))*100, digits = 1)```% of types). This set of words is shown in Table X.

\ Table X
```{r intersectTable, echo=FALSE, warning=FALSE, message=FALSE}
intersect_words_table %>% 
  apa_table(format = 'pandoc', caption = "The 28 Words Common across All Instructional Sources with Rank Frequency", note = "Words are arranged in descending frequency, and rank frequency is provided in parentheses and is calculated from Wisconsin Children's Book Corpus.", col.names = NULL)
```


```{r}
plot_data = all_lists %>% 
  group_by(word) %>% 
  summarise(count = first(count)) %>%
  ungroup() %>% 
  group_by(count) %>% 
  summarise(n = n()) %>% 
  mutate(prop = n/length(unique(all_lists$word)),
         n_prop = paste(n, ' (', round(prop*100, digits = 0), '%)', sep = ''))



```

This overlap can be seen visually in the diagram in Figure X. The very center of the figure represents those words that are common across all sources. Likewise, any overlapping portion of the diagram represents the overlap from the sources specified by that region, with the outer portions of the figure showing words unique to a specific source and no others. 

```{r venn, echo=FALSE, warning=FALSE, message=FALSE, fig.align='center', fig.cap='A diagram depicting the overlap in words across sources. Raw counts are provided, with a percentage provided in parentheses showing the percentage of all unique words across all sources that a particular overlapping set represents. Sources can be identified by the outline color of the set. The figure was generated using the ggVennDiagram package in R (Gao, 2022).'}

tmp = all_lists_
names(tmp) = c("Kilpatrick", "Dolch", "Fry", "Fundations", "Wonders", "Fountas & Pinnell")

COLORS_SOURCE2 = c('darkblue', 'darkred', 'darkorange', 'turquoise', 'red', 'green')
ggVennDiagram(tmp, label_size = 2, label_alpha = 0, set_size = 2.5) +
  scale_fill_gradient(low = 'white', high = 'firebrick') +
  scale_color_manual(values = COLORS_SOURCE2) +
  labs(fill = 'Count') +
  theme(legend.title = element_text(size = 11))
  

```

The number of words that are unique to a single resource is high by comparison, with ```r max(plot_data$n)``` (representing ```r max(plot_data$prop)```% of all unique words), with the number of unique words decreasing as the number of resources increases (Fig X). 

```{r echo=FALSE, warning=FALSE, message=FALSE, fig.align='center', fig.height=3, fig.cap='Few words are shared by all resources (6 total, the far right hand of the x-axis). At the other extreme, many words are unique to one source (560, left hand side of figure).'}
plot_data %>% 
  ggplot(aes(count, n)) +
  geom_bar(stat = 'identity', color = 'black', fill = 'grey57') +
  #geom_smooth(color = 'grey36', linetype = 'dashed') +
  geom_text(aes(label = n_prop), size = 3, vjust = -.9, alpha = .8) +
  ylim(c(0, 600)) +
  labs(x = 'Number of resources', y = 'Number of words') +
  theme_apa() +
  theme(legend.position = 'none')
```

In terms of individual resources, Kilpatrick represents the outlier; it contains the most words (326) that are unique to a single source and no others (see outer rim of Figure X in region labeled "Kilpatrick"). This set of words represents a relatively high proportion of all words across all sources (32%).


## The overlap across sources in terms of their properties
It is possible that the words across resources might be different while the underlying properties of those words might not vary. If this is the case then variability in the words selected for instruction would be less meaningful; Students might have similar language experience in this type of instruction by virtue of the underlying language structures the words convey. In order to examine this possibility we will look at each set of words binned by their overlap among the 6 instructional resources (the number of resources that the word appeared in) and examine that set of words in terms of their language properties, starting with word frequency.

In order to analyze instructional words with respect to their linguistic properties, a number of datasets were identified and merged with the database of words aggregated for the study. These data are utilized across the studies presented here, so we will review the different data and their sources up front. One important issue concerns how instructional words compare to words children and adults tend to encounter in other language experiences - reading related and otherwise. In order to make comparisons along these lines we assembled several relevant benchmark sets using language databases that represent language experiences for different groups and in different modes of communication, both via printed and spoken language. The corpora we selected for this purpose are The Wisconsin Children's Book Corpus [@Lewis2022], the Child Language Data Exchange System [@MacWhinney2000], and words from the Educator's Word Frequency Guide from Touchstone Applied Science Associates [@Zeno1995].

The Wisconsin Children's Book Corpus (WCBC) contains texts commonly consumed by pre-readers (up to the age of 6). Data from the Child Language Data Exchange System (CHILDES) represents language from children's spoken language environment (the data used here are from transcripts for children in the US up to the age of 6 years). The Educator's Word Frequency Guide (from Touchstone Applied Science Associates; TASA) captures information about words in literature children are commonly exposed to in grade school.



```{r frequencyCorpusTable, echo=FALSE, warning=FALSE}
frequency_by_corpus(all_lists) %>% 
  apa_table(format = 'pandoc', caption = "Descriptive Characteristics for Word Frequencies using for All Words in the Database", note = "Values provided as raw frequencies. Min values are always 1 and have been excluded. WCBC = Wisconsin Childrens Book Corpus; TASA = Frequencies from the Educator's Word Frequency Guide by Touchstone Applied Science Associates; CHILDES = The Child Language Data Exchange System.")

```





## Discussion


