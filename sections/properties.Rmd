# The Overlap across Sources in Terms of their Properties

It is possible that the words across resources might be different while the underlying properties of those words might not vary. If this is the case then variability in the words selected for instruction would be less meaningful; Students might have similar language experience in instruction by virtue of the underlying language structures the words convey. In order to examine this possibility we will look at each set of words binned by their overlap among the six instructional resources (the number of resources that the word appeared in) and examine that set of words in terms of their language properties, starting with word frequency.

In order to analyze instructional words with respect to their linguistic properties, a number of datasets were identified and merged with the database of words aggregated for the study. One important issue concerns how instructional words compare to words children and adults tend to encounter in other language experiences - reading related and otherwise. In order to make comparisons along these lines we assembled several relevant benchmark sets using language databases that represent language experiences for different groups and in different modes of communication, both via printed and spoken language. The corpora we selected for this purpose (in terms of examining word frequency) are The Wisconsin Children's Book Corpus [@Lewis2022], the Child Language Data Exchange System [@MacWhinney2000], the Educator's Word Frequency Guide from Touchstone Applied Science Associates [@Zeno1995], and the Corpus of Contemporary American English [@Davies2010].

The Wisconsin Children's Book Corpus (WCBC) contains texts commonly read by and to pre-readers (up to the age of six). Data from the Child Language Data Exchange System (CHILDES) represents language from children's spoken language environment (the data used here are from transcripts for children in the US up to the age of six). The Educator's Word Frequency Guide (from Touchstone Applied Science Associates; TASA) captures information about words in literature children are commonly exposed to in grade school, and The Corpus of Contemporary American English is a large corpus of texts aimed at adult readers (COCA; this subset is adult fiction).

```{r frequencyCorpusTable, echo=FALSE, warning=FALSE}
frequency_by_corpus(all_lists) %>% 
  rbind(coca %>% 
              summarise(M = mean(freq, na.rm = T),
                        SD = sd(freq, na.rm = T),
                        max = max(freq)) %>% 
              mutate(Corpus = "COCA")) %>%  # add COCA because it was not included in all_lists
  apa_table(caption = "Descriptive Characteristics for Word Frequencies using for All Words in the Database", note = "Values provided as raw frequencies. Min values are always 1 and have been excluded. WCBC = Wisconsin Childrens Book Corpus; TASA = Frequencies from the Educator's Word Frequency Guide by Touchstone Applied Science Associates; CHILDES = The Child Language Data Exchange System; COCA = The Corpus of Contemporary American English", escape = FALSE)

```


# The properties of words across sources

First we will look at the frequency of words in each instructional resource and their relative distribution across them. Then, we will move on to other word properties.

## Frequency

```{r frequencyModels, include=FALSE}

tmp = Zs %>% 
  filter(var == 'wcbc_rank')
  

z_tests = split(tmp$Z, tmp$source) %>% 
  map(t.test)

z_tests_to_table(z_tests) %>% 
  select(-CI_low, -CI_hi, -p_derived) %>% 
  apa_table(escape = FALSE)


```

Word frequency is a property that differs based on the source from which it is drawn. A word's frequency in a corpus assembled from transcripts of spoken language interactions with children will have a different frequency (and be drawn from a different distribution) than that word's frequency in a corpus of adult fiction. In order to capture this variability, the four different sources of word frequency are considered here for analysis, each representing different sources of learning. For example, words present in COCA are oriented towards adult readers. Therefore a set of words that is common among this set and relatively less common among the TASA data (academic texts for young people) would indicate that the set is more likely oriented towards topics and forms that are more often experienced by adult readers rather than children in academic contexts.

For all the frequency data in this section, rank frequencies are used. Therefore, low values indicate high frequencies. Rank frequencies exhibit a uniform distribution (one word per rank), and this type of frequency measure avoids the skew found in raw frequencies. In order to facilitate comparison across sources and relative to a normative distribution (i.e., a distribution from a reference corpus), rank frequencies were standardized in the following way. All words from a given corpus were standardized for rank frequency by taking the rank frequency value, subtracting the mean for that corpus and dividing by the standard deviation of that corpus. This results in a distribution of rank frequency for each word in a given corpus (e.g., the rank frequency within the COCA corpus) set in relation to the variability of rank frequency in that corpus. Once achieved, measures of rank frequency within each instructional source were calculated using the standardized rank frequency from each corpus' distribution just described.

This allows comparisons on several levels. First, the distribution of standardized rank frequency for a given source gives a measure of how different that distribution is for the normative distribution. Additionally, the distribution for each source can be compared to the others given that they've been put on a common scale. The resulting interpretation of the mean of rank frequency for a source is the difference in standard deviation units (of rank) between that source and the corpus from which standardized values have been calculated.

This is useful when one considers the characteristics of a given text corpus from which the frequency distribution is constructed (child-directed text, child-directed speech, adult-directed text, etc.). A table of descriptive statistics across corpora and sources are shown in Table X.

```{r descriptivesFreqSource, echo=FALSE, warning=FALSE, message=FALSE}
sources = desc_by_var(Zs, 'wcbc_rank', combine_ = T)$source
wcbc_ = desc_by_var(Zs, 'wcbc_rank', combine_ = T)$var
tasa = desc_by_var(Zs, 'tasa_rank', combine_ = T)$var
coca = desc_by_var(Zs, 'coca_rank', combine_ = T)$var
childes = desc_by_var(Zs, 'childes_rank', combine_ = T)$var

data.frame(cbind(sources, wcbc_, tasa, coca, childes)) %>% 
  rename(Source = sources,
         WCBC = wcbc_,
         TASA = tasa,
         COCA = coca,
         CHILDES = childes) %>% 
  apa_table(caption = 'Descriptive Statistics of Rank Frequency by Source across Corpora', 
            note = 'Means and standard deviations (in parentheses) are shown over standardized rank frequency values for all words in a given instructional source. Frequencies are standardized based on all words in a given corpus before subsetting and calculating the mean and spread by instructional source. As a result, the mean rank frequency shown represents how far from the mean of all words in a given corpus (zero) the distribution within an instructional source is.',
            escape = FALSE)



```

All instructional resources contain words that are, on average, more frequent (lower standardized rank frequency) than the average word from each corpus, as indicated by each mean value being negative. This is expected given than all of the resources are supposed to contain common words (based on their own reporting).

These comparisons bear out in a statistical model of these distributions against zero (the normative mean, which is always zero due to standardization). Figure X shows the results from this statistical test for the six resources in the distribution of frequencies in WCBC. This single corpus is used because it presents the most modest reference point, because all corpora demonstrate the same general trend, and because it is a corpus of interest given its contents. Grey points within each panel are individual observations (words) within each source for a given value for standardized rank frequency. The colored points represent the mean for a source on a given frequency, and the bar around that mean represents the standard error of the point estimate for that source on that frequency. The dotted line represents the mean across all frequencies for that instructional source. This facilitates a direct comparison across instructional sources.

Dolch displays the lowest average rank frequency and the least amount of variability in frequency. On the other end is Kilpatrick. This set of words is much higher in average rank frequency (i.e., lower in raw frequency) than any of the other resources. The variability in rank frequency for this set is noteworthy as well. Not only are the averages for Kilpatrick much higher in rank frequency than any of the other instructional resources, the spread of frequency values for that source is higher as well. For several corpora, the Kilpatrick distribution includes words *above the mean* (true for TASA, WCBC, and CHILDES).

Also, in general it is clear that instructional sources are oriented towards words that are very high frequency in terms of adult texts, but less so for child texts. This effect is observed given that the means for COCA (adult fiction) are all well below average (the red dashed line) in each corpus, but the average value for WCBC (child-directed texts) is always well above the mean line across language corpora for all sources (i.e., the red point for WCBC is always well above the red dashed line in each panel). Assuming that TASA norms more accurately represent what children read by themselves (rather than what's read to them; i.e., WCBC), a further point can be made: Kilpatrick shows the greatest relative difference between the frequency of words in child texts versus adult texts. This is shown by the difference between the point for COCA and TASA in the Kilpatrick panel, suggesting that the Kilpatrick source is more tuned towards words commonly found in texts read by adults as opposed to those read by children.

```{r wcbcFreqTtest, echo=FALSE, warning=FALSE, message=FALSE}
#z_tables_freq %>%
z_table_wcbc %>% 
  select(-CI_hi, -CI_low, -p_derived, -var) %>% 
  apa_table(caption = "Model Outputs by Source for Statistical Test against Mean Rank Frequency from the Wisconsin Children's Book Corpus", note = "Statistical test used was t.test() from base R (R Core Team, 2021). Rank frequencies were Z transformed prior to test, so resulting coefficients express the difference in standard deviations of rank frequency from WCBC between the source mean on rank frequency and the WCBC mean (0 due to Z transformation).", escape = FALSE)

```

```{r echo=FALSE, message=FALSE, warning=FALSE, fig.cap='The raw distribution of words across sources and corpus rank frequency (standardized) are shown as points (in grey) with statistical estimate as colored points within each distribution. Because standard errors are imperceptibly small, standard deviations for the standardized rank frequency values within each distribution are shown. All distributions are significantly different than the corpus mean (0).'}
VARS = c('tasa_rank', 'wcbc_rank', 'childes_rank', 'coca_rank')


hlines = nsd %>% 
  filter(var %in% VARS) %>% 
  group_by(var) %>% 
  summarise(varmean = mean(M_, na.rm = T)) %>% 
  mutate(var = case_when(var == 'wcbc_rank' ~ 'WCBC',
                         var == 'tasa_rank' ~ 'TASA',
                         var == 'childes_rank' ~ 'CHILDES',
                         var == 'coca_rank' ~ 'COCA'))

plot_data = Zs %>% 
  filter(var %in% VARS) %>% 
  select(var, source, M = Z) %>% 
  mutate(var = case_when(var == 'wcbc_rank' ~ 'WCBC',
                         var == 'tasa_rank' ~ 'TASA',
                         var == 'childes_rank' ~ 'CHILDES',
                         var == 'coca_rank' ~ 'COCA')) %>% 
  mutate(source_ = fct_relevel(source, 'Kilpatrick', after = 4))



Zs %>% 
  group_by(source, var) %>% 
  summarise(M = mean(Z, na.rm = T)) %>% 
  left_join(nsd) %>% 
  mutate(SEM = SD/(sqrt(n))) %>%
  filter(var %in% VARS) %>% 
  mutate(var = case_when(var == 'wcbc_rank' ~ 'WCBC',
                         var == 'tasa_rank' ~ 'TASA',
                         var == 'childes_rank' ~ 'CHILDES',
                         var == 'coca_rank' ~ 'COCA'),
                source = as.factor(source)) %>% 
  mutate(source_ = fct_relevel(source, 'Kilpatrick', after = 4)) %>% 
  ggplot(aes(source_, M, color = source_, group = var)) +
  scale_color_manual(values = COLORS_SOURCE) +
  geom_point(data = plot_data, position = position_jitter(width = .04, height = .01), size = .01, color = 'grey') +
  geom_point(size = 2) +
  geom_line(color = 'grey') +
  geom_errorbar(aes(ymin = M-SD, ymax = M + SD, color = source_), width = .5) +
  facet_grid(~var) +
  ylim(c(-2, .5)) +
  labs(color = 'Variable', x = 'Source', y = 'Rank frequency (standardized)') +
  geom_hline(yintercept = 0, linetype = 'dashed', color = 'red') +
  geom_hline(data = hlines, aes(yintercept = varmean), color = 'black', linetype = 'dotted') +
  theme_apa() +
  theme(legend.position = 'top',
        axis.ticks.x = element_blank(), 
        axis.text.x = element_blank(),
        strip.background=element_blank(),
        text = element_text(family = 'Times'))

```

### Coverage of most frequent words in child-directed print and speech

We could reasonably expect that these resources draw from the most frequent words in child-directed speech and (especially) print. One way of examining this is calculating the proportion of the most frequent *n* words in child-oriented corpora that a given resource contains. Here we've done this for CHILDES, TASA, and WCBC, each representing different important aspects of experiences of elementary-aged children (spoken language, academic prose, and recreational texts read to children). Given that these corpora represent relevant learning environments for an early reader, each instructional set *should* contain a nontrivial proportion of the most frequent words in the corpus - here the most frequent 100, 500, and 1000 words.

```{r coverageKidCorpus, echo=FALSE, warning=FALSE, message=FALSE}
ROWS = length(unique(all_lists$source))*length(unique(top_N$corpus))*length(unique(top_N$top_n))
COLS = c("source", "corpus", "top_n", "in_program", "proportion")


coverage = data.frame(matrix(nrow = ROWS, ncol = length(COLS)))
colnames(coverage) = COLS

i = 1

for (source_ in unique(all_lists$source)){
  
  trigger = all_lists %>% 
        filter(source == source_) %>% 
        distinct(word) %>% 
        pull(word)
  
  for (corpus_ in unique(top_N$corpus)){
    for (N in unique(top_N$top_n)){
      
      # get all the words for a given source (program)
      
      
      # get all the words from a given corpus as a specific level of "top N" (i.e. 100, 500, 1000)
      target = top_N %>% 
        filter(corpus == corpus_) %>% 
        filter(top_n == N) %>% 
        pull(word)

      coverage$source[i] = source_
      coverage$corpus[i] = corpus_
      coverage$top_n[i] = as.numeric(N)
      coverage$in_program[i] = length(intersect(target, trigger))
      coverage$proportion[i] = length(intersect(target, trigger))/as.numeric(N)
      
      print(i)
      i = i + 1
      
    }}}

```

The trends across corpora for all six programs follow a common pattern. Programs tend to exhibit more coverage for the most frequent 100 words, less so than the most frequent 500 and even less for the most frequent 1000. This fact is not surprising. Likewise, the coverage for each program for the three child corpora follow a common trend. Coverage for TASA tends to be greater than WCBC, which tends to be greater than CHILDES.

Wonders contains the most words, with 801, so it is perhaps unsurprising that its coverage is greatest. With this quantity of words, it stands out that it only contains 58%, 65%, and 56% of the most frequent 500 words from the three corpora respectively. That list is the only one with enough to potentially contain 100% of those words (which it does not). By contrast, the Dolch and Fry words obtain comparable coverage with fewer words, each with less than half of that than Wonders. Nonetheless, Wonders, Fry, and Dolch demonstrate very similar levels of coverage. All three have greater than 75% coverage for all three corpora on the top 100 words and around half of the top 500 words. Fountas and Pinnell exhibit slightly lower levels of coverage than those three, with Fundations demonstrating even less coverage than Fountas and Pinnell. The coverage for Kilpatrick is very low, even for the most frequent 100 words. This is fact can be emphasized given that Kilpatrick contains the second most number of words behind Wonders, and over 100 words more than the Dolch list.

```{r coverageKidCorpusTable, echo=FALSE, warning=FALSE, message=FALSE}
coverage %>% 
  select(-in_program) %>% 
  mutate(proportion = round(proportion, digits = 2)) %>% 
  pivot_wider(names_from = top_n, values_from = proportion) %>% 
  mutate(proportion = str_c(`100`, `500`, `1000`, sep = " - ")) %>% 
  select(source, corpus, proportion) %>% 
  pivot_wider(names_from = corpus, values_from = proportion) %>% 
  left_join(coverage %>% 
              group_by(source) %>% 
              summarise(proportion_ = mean(proportion)) %>% 
              arrange(desc(proportion_)) %>% 
              mutate(order = seq_len(n()))) %>% 
  arrange(order) %>% 
  mutate(source = case_when(source == 'dolch' ~ 'Dolch',
                            source == 'fry' ~ 'Fry',
                            source == 'fundations' ~ 'Fundations',
                            source == 'kilpatrick' ~ 'Kilpatrick',
                            source == 'wonders' ~ 'Wonders',
                            source == 'fountas_pinnell' ~ 'F&P')) %>% 
  left_join(all_lists %>% 
              group_by(source) %>% 
              summarise(n_ = n()) %>% 
              mutate(source = case_when(source == 'dolch' ~ 'Dolch',
                            source == 'fry' ~ 'Fry',
                            source == 'fundations' ~ 'Fundations',
                            source == 'kilpatrick' ~ 'Kilpatrick',
                            source == 'wonders' ~ 'Wonders',
                            source == 'fountas_pinnell' ~ 'F&P'))) %>% 
  mutate(source = str_c(source, " (", n_, ")")) %>%             
  select(Resource = source, `WCBC (100-500-1000)` = wcbc, `TASA (100-500-1000)` = tasa, `CHILDES (100-500-1000)` = childes) %>% 
  apa_table(caption = "Proportion Coverage of Top 100, 500, and 1000 Words from WCBC, TASA, and CHILDES for the Six Resources.",
            note = "Number of words in each resource is provided next to the name of the resource for reference.",
            col_spanners = list("Corpus" = c(2, 4)))

```

```{r coverageKidCorpusFigure, echo=FALSE, warning=FALSE, message=FALSE, fig.cap="The coverage that each program (panel) for each level of most frequent 100, 500, and 1000 words for three child-directed corpora are shown: CHILDES, TASA, and WCBC. Programs exhibit variable coverage of these words for the three corpora, with Wonders, Fry, and Dolch showing comparable levels of coverage at one extreme, and Kilpatrick at the other."}

coverage %>% 
  mutate(corpus = case_when(corpus == 'wcbc' ~ 'WCBC',
                         corpus == 'tasa' ~ 'TASA',
                         corpus == 'childes' ~ 'CHILDES',
                         corpus == 'coca' ~ 'COCA'),
         source = case_when(source == 'dolch' ~ 'Dolch',
                            source == 'fry' ~ 'Fry',
                            source == 'fundations' ~ 'Fundations',
                            source == 'kilpatrick' ~ 'Kilpatrick',
                            source == 'wonders' ~ 'Wonders',
                            source == 'fountas_pinnell' ~ 'F&P')) %>% 
  ggplot(aes(corpus, proportion, fill = as.factor(top_n))) +
  geom_bar(stat = "identity", position = "dodge", color = "black") +
  facet_grid(~factor(source, levels = c("Wonders", "Fry", "Dolch", "F&P", "Fundations", "Kilpatrick"))) +
  theme_apa() +
  labs(x = "Corpus", y = "Proportion covered", fill = "N most frequent") +
  theme(text = element_text(family = "Times"),
        axis.text.x = element_text(angle = 90, vjust = .5, hjust = 1)) +
  scale_fill_manual(values = c("burlywood", "gold2", "brown"))
```

## Other word characteristics across sources

To facilitate comparison of other word properties (other than frequency), the words from the Wisconsin Children's Book Corpus (Lewis et al., 2021) were used as a benchmark set. All the words from the WCBC (*n* = `r nrow(wcbc)`) were aggregated along with a range of word-level measurements (age of acquisition, orthography-to-phonology consistency, imageability, number of letters, and number of syllables). In order to present data that captures the normative comparison to WCBC, similar to what was done with word frequencies, measurements for word-level variables were standardized (mean-centered and put into relation to the standard deviation) based on the distribution of that variable over all words in the WCBC corpus (rather than four different corpora as was done with frequency). This is intended to capture the variability on a given variable relative to the distribution in the benchmark (WCBC-based) sample.

```{r desc_other, echo=FALSE, warning=FALSE, message=FALSE}

VARS = c('aoa', 'consistency', 'letters', 'syllables', 'imageability')

sources = desc_by_var(Zs, VARS[1], combine_ = T)$source
aoa = desc_by_var(Zs, VARS[1], combine_ = T)$var
consistency = desc_by_var(Zs, VARS[2], combine_ = T)$var
letters = desc_by_var(Zs, VARS[3], combine_ = T)$var
syllables = desc_by_var(Zs, VARS[4], combine_ = T)$var
imageability = desc_by_var(Zs, VARS[5], combine_ = T)$var


data.frame(cbind(sources, aoa, consistency, letters, syllables, imageability)) %>%
  rename(Source = sources,
         AoA = aoa,
         Consistency = consistency,
         Letters = letters,
         Syllables = syllables,
         Imageability = imageability) %>% 
  apa_table(caption = 'Descriptive Statistics of Other Word Variables for each Source across WCBC', 
            note = "Means and standard deviations (in parentheses) are shown over Z transformed rank frequency values for all words in a given instructional source. Standardization happens relative to the Wisconsin Children's Book Corpus. Therefore the mean value for a source for a given variable indicates the average distance from the overall mean within WCBC.", escape = FALSE)

```

Table XX provides the means and standard deviations for sources across all word variables. Figure XX shows these values for a given variable for each instructional source (colored point in each panel), where colors are conditioned on the five different variables of interest. Within each panel, the dotted line refers to the average across points, here representing the average across all variables. This way of presenting these data facilitates interpretation given that all the points for all the variables fall on the negative side of the distribution for all sources; all points are below the mean on the standardized scale for all words in WCBC. The dashed line again shows the mean for all variables in all words in WCBC (zero due to standardization).

Fundations is associated with the lowest values across all sources on average. Looking at the extremes within that source, we see that the list of words favors words with more syllables and higher age-of-acquisition values relative to the imageability of words. That source also shows the lowest overall consistency of words relative to other sources.

The figure below shows the same data as the previous, but oriented in a way that facilitates comparison for a variable across sources, rather than the other way around. The visual elements are all the same except here the color of points are conditioned on sources rather than variables, and the red dashed means are averaged across sources for a variable, rather than variables for a source as we saw before.

```{r profileFigureLexical, echo=FALSE, message=FALSE, warning=FALSE, fig.cap='Means and standard errors for a range of word variables within sources are shown. Means are calculated over standardized measures within WCBC, therefore the position of the point for a source for a variable can be interpreted as the average distance away from the mean of all words within WCBC (i.e., 0 shown with a red dashed line) for that variable in terms of standard deviation units. The mean on a given variable across all sources is shown as a grey dotted line just for convenience. Estimates were derived using t.test() in base R.'}

bardata = z_tables_lexical %>% 
  select(source = Source, se = `\\textit{SE}`, var, M = `\\textit{b}`) %>% 
  mutate(se = as.numeric(se),
         M = latex_to_num(M)) %>% 
  mutate(var = case_when(var == 'consistency' ~ 'Consistency',
                         var == 'syllables' ~ 'Syllables',
                         var == 'aoa' ~ 'AoA',
                         var == 'imageability' ~ 'Imageability',
                         var == 'letters' ~ 'Letters')) 
  
hlines = nsd %>% 
  filter(var %in% VARS) %>% 
  group_by(var) %>% 
  summarise(sourcemean = mean(M_, na.rm = T)) %>% 
  mutate(var = case_when(var == 'consistency' ~ 'Consistency',
                         var == 'syllables' ~ 'Syllables',
                         var == 'aoa' ~ 'AoA',
                         var == 'imageability' ~ 'Imageability',
                         var == 'letters' ~ 'Letters')) 

Zs %>% 
  group_by(source, var) %>% 
  summarise(source_order = first(source_order)) %>% 
  filter(var %in% VARS) %>% 
  mutate(var = case_when(var == 'consistency' ~ 'Consistency',
                         var == 'syllables' ~ 'Syllables',
                         var == 'aoa' ~ 'AoA',
                         var == 'imageability' ~ 'Imageability',
                         var == 'letters' ~ 'Letters')) %>% 
  left_join(bardata) %>% 
  ggplot(aes(reorder(source, source_order), M, color = reorder(source, source_order), group = reorder(var, source_order))) +
  geom_hline(data = hlines, aes(yintercept = sourcemean), color = 'black', linetype = 'dotted') +
  scale_color_manual(values = COLORS_SOURCE) +
  geom_point(size = 2) +
  geom_line(color = 'grey') +
  geom_errorbar(aes(ymin = M-se, ymax = M+se), size = .5, width = .8) +
  labs(color = 'Source', x = 'Variable', y = 'Standardized value (within WCBC)') +
  facet_grid(~var)  +
  geom_hline(yintercept = 0, linetype = 'dashed', color = 'red') +
  #ylim(c(-1.3, 0)) +
  theme_apa() +
  theme(legend.position = 'top',
        axis.ticks.x = element_blank(), 
        axis.text.x = element_blank(),
        text = element_text(family = 'Times'))

```

The differences between the source distribution on each word-level variable relative to the normative distribution (WCBC) are all statistically significant based on a statistical test of the mean against zero (paralleling the tests conducted previously on the frequency distributions).

```{r profileTableStatTest, echo=FALSE, message=FALSE, warning=FALSE}
Source = z_tables_lexical %>% filter(var == 'aoa') %>% pull(Source)
AoA = z_tables_lexical %>% filter(var == 'aoa') %>% rename(b = `\\textit{b}`, se = `\\textit{SE}`) %>% mutate(o = paste(b, ' (', se, ')', sep = '')) %>%  pull(o)
Consistency = z_tables_lexical %>% filter(var == 'consistency') %>% rename(b = `\\textit{b}`, se = `\\textit{SE}`) %>% mutate(o = paste(b, ' (', se, ')', sep = '')) %>%  pull(o)
Imageability = z_tables_lexical %>% filter(var == 'imageability') %>% rename(b = `\\textit{b}`, se = `\\textit{SE}`) %>% mutate(o = paste(b, ' (', se, ')', sep = '')) %>%  pull(o)
Letters = z_tables_lexical %>% filter(var == 'letters') %>% rename(b = `\\textit{b}`, se = `\\textit{SE}`) %>% mutate(o = paste(b, ' (', se, ')', sep = '')) %>%  pull(o)
Syllables = z_tables_lexical %>% filter(var == 'syllables') %>% rename(b = `\\textit{b}`, se = `\\textit{SE}`) %>% mutate(o = paste(b, ' (', se, ')', sep = '')) %>%  pull(o)

data.frame(cbind(Source, AoA, Consistency, Imageability, Letters, Syllables)) %>% 
  mutate(Source = case_when(Source == 'Dolch' ~ 'Dolch',
                            Source == 'Fry' ~ 'Fry',
                            Source == 'Fundations' ~ 'Fundations',
                            Source == 'Kilpatrick' ~ 'Kilpatrick',
                            Source == 'Wonders' ~ 'Wonders',
                            Source == 'Fountas_pinnell' ~ 'Fountas & Pinnell')) %>% 
  apa_table(caption = 'Model Estimates for Statistical Tests of Source Means against Means from Normative Sample', 
            note = 'Estimates obtained from using t.test() from base R, with standard errors in parentheses. Bolded parameter estimates are statistically significant. For a full accounting of parameter estimates see appendix. Values were Z transformed on the distribution from the WCBC prior to subsetting and testing by source.', escape = FALSE)
  
```
