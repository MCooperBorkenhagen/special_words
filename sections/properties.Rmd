# Question 2: The Overlap across Sources in Terms of their Properties
Could there be more commonality across resources than suggested by the above data. Perhaps the resources agree on which types of words should be identified–the properties of words that cause them to require special attention–while differing in the exact choice of words to include. If this is the case then variability in the words selected for instruction would be less meaningful; Students would have similar experiences in print vocabulary by virtue of the underlying language structures and properties associated with instructional words. In order to examine this possibility we looked at each set of words in terms of a range of properties known to be important in reading development: frequency, age-of-acquisition, consistency, imageability, and length (number of letters and number of syllables).

## Measures
### Frequency
Word frequency is important in instruction because words that are frequent (as measured in a sample of texts) will tend to be more common across texts the child reads. However, word frequency can only be estimated, and is not a fixed property of a word (like number of letters). In order to estimate frequency, data from the Educator's Word Frequency Guide from Touchstone Applied Science Associates [@Zeno1995] were used^["See supplement for additional analyses that consider other sources of word frequency"]. Words from the Educator's Word Frequency Guide (TASA) were subset for grade levels K through 3 in order to match the grade levels associated with our sample of instructional words. This corpus exhibits a mean frequency value of `r frequency_by_corpus(all_lists) %>% filter(Corpus == "TASA") %>%  pull(M)` (SD = `r frequency_by_corpus(all_lists) %>% filter(Corpus == "TASA") %>%  pull(SD)`, max = `r frequency_by_corpus(all_lists) %>% filter(Corpus == "TASA") %>%  pull(max)`). See the beginning of the section on research question RQ1 for summary statistics for this corpus for each resource.

All the frequency data analyzed using rank frequencies, where low values indicate high frequencies. Rank frequencies exhibit a uniform distribution (one word per rank). This type of frequency measure avoids the skew found in raw frequencies. This measure of frequency is also useful for our purpose because the variation of interest exists in the portion of the distribution where there are no ties (i.e., the highest frequency words/ those with the lowest rank frequency). In order to facilitate comparison across sources and relative to a normative distribution (i.e., a distribution from a reference corpus), rank frequencies were standardized.

All words from the TASA corpus were standardized for rank frequency by taking the rank frequency value, subtracting the mean from the corpus and dividing by the standard deviation. This results in a distribution of rank frequency for each word in the corpus set in relation to the variability of rank frequency in the corpus. Once the frequencies were standardized in this way, measures of rank frequency within each instructional resource were calculated using this standardized rank frequency from TASA.

This allows comparisons on several levels. First, the distribution of standardized rank frequency for a given source gives a measure of how different that distribution is for the normative (i.e., TASA) distribution. This is important in order to consider, for example, whether or not an instructional resource tends to select words that are similar to the average word from this normative distribution (or some other relevant comparison). Additionally, the distribution for each resource can be compared to the others given that they've been put on a common scale. The resulting interpretation of the mean of rank frequency for a source is the difference in standard deviation units (of rank) between that source and the TASA corpus. Because rank frequencies are used, a low value is associated with a high frequency. 

A table of descriptive statistics for each list for the TASA word frequencies (raw and standardized rank) are shown in Table XX.

```{r descriptivesFreqSource, echo=FALSE, warning=FALSE, message=FALSE}
# old code left here for supplement which should contain values across several corpora

sources = desc_by_var(Zs, 'tasa_rank', combine_ = T)$source
#wcbc_ = desc_by_var(Zs, 'wcbc_rank', combine_ = T)$var
tasa_ = desc_by_var(Zs, 'tasa_rank', combine_ = T)$var
#coca = desc_by_var(Zs, 'coca_rank', combine_ = T)$var
#childes = desc_by_var(Zs, 'childes_rank', combine_ = T)$var

tasa_2 = all_lists %>% 
  arrange(desc(tasa_freq)) %>% 
  mutate(rank = seq_len(n())) %>% 
  group_by(source) %>% 
  summarise(rank_mean = round(mean(rank, na.rm = T)),
            rank_sd = round(sd(rank, na.rm = T)),
            raw_mean = round(mean(tasa_freq, na.rm = T)),
            raw_sd = round(sd(tasa_freq, na.rm = T))) %>% 
  mutate(Rank = str_c(rank_mean, " (", rank_sd, ")"),
         Raw = str_c(raw_mean, " (", raw_sd, ")")) %>% 
  mutate(Source = case_when(source == 'dolch' ~ 'Dolch',
                            source == 'fountas_pinnell' ~ 'Fountas & Pinnell',
                            source == 'fry' ~ 'Fry',
                            source == 'fundations' ~ 'Fundations',
                            source == 'kilpatrick' ~ 'Kilpatrick',
                            source == 'wonders' ~ 'Wonders',
                            TRUE ~ NA
                              )) %>% 
  select(Source, Rank, Raw)


data.frame(cbind(sources, tasa_)) %>% 
  rename(Source = sources,
         `Rank (Z)` = tasa_,
         ) %>% 
  left_join(tasa_2) %>%
  select(Source, Rank, everything()) %>% 
  apa_table(caption = "Descriptive Statistics of Rank Frequency by Resource for TASA Corpus", 
            note = 'Means and standard deviations (in parentheses) are shown for rank frequency, standardized rank frequency (Rank Z), and raw frequency values for all words in a given instructional resource for the TASA corpus. Frequencies are standardized based on all words in TASA before subsetting and calculating the mean and spread by instructional source. As a result, the mean rank frequency shown represents how far from the mean of all words in TASA the distribution within an instructional resource is.',
            escape = FALSE)



```


## Other Word Characteristics across Sources: Age of Acquisition, Consistency, Imageability, Number of Letters, and Number of Syllables
### Measures of Other Word Characteristics
To facilitate comparison of other word properties, a similar process to the standardization procedure for frequency was used for several other word-level measurements. These include orthography-to-phonology consistency [@Chee2020], age of acquisition [@Kuperman2012],  imageability [@Stadthagen2006], number of letters, and number of syllables. Age of acquisition and imageability are measured by self-report from large samples of literate adults. For the consistency variable, the average feedforward consistency for body-rime units across syllables for the word was used. This measure captures an aggregate measure of the consistency of the word regardless of its length. Measurements for word-level variables were standardized by mean-centering and being put into relation to the standard deviation for words from TASA. As with frequency, this is intended to capture the variability on a given variable relative to the distribution in the benchmark (TASA-based) sample. For these variables, we don't describe their distributions in terms of their rank ordering given the specific utility of ranks when discussing frequency distributions (which are highly skewed, Zipfian distributions). Nonetheless, the procedure for standardization is the same for all variables, with the exception that for frequency, low values (e.g., rank 1) are associated with high frequency.

Table XX provides the means and standard deviations for sources across all word variables. Figure 5 shows these values for a given variable for each instructional source (colored point in each panel). Colors are conditioned on the five different variables of interest within each panel and the dotted line refers to the average across points, here representing the average across all variables. The dashed line again shows the mean for all variables in all words in TASA (zero due to standardization).

```{r desc_other, echo=FALSE, warning=FALSE, message=FALSE}


sources = desc_by_var(Zs, VARS[1], combine_ = T)$source
aoa = desc_by_var(Zs, "aoa", combine_ = T)$var


consistency = desc_by_var(Zs, "consistency", combine_ = T)$var
letters = desc_by_var(Zs, "letters", combine_ = T)$var
syllables = desc_by_var(Zs, "syllables", combine_ = T)$var
imageability = desc_by_var(Zs, "imageability", combine_ = T)$var


data.frame(cbind(sources, aoa, consistency, letters, syllables, imageability)) %>%
  rename(Source = sources,
         AoA = aoa,
         Consistency = consistency,
         Letters = letters,
         Syllables = syllables,
         Imageability = imageability) %>% 
  apa_table(caption = 'Descriptive Statistics of Other Word Variables for each Source across TASA', 
            note = "Means and standard deviations (in parentheses) are shown over Z transformed rank frequency values for all words in a given instructional source. Standardization happens relative to the TASA. Therefore the mean value for a source for a given variable indicates the average distance from the overall mean within TASA.", escape = FALSE)

```

### Summary of Scales of Measured Word Variables
For clarity, a summary of the scales of measures used here given that the interpretation of variables depends on the scale and its organization (and possible confusion introduced by the language used to describe the distribution). All variables were standardized in the TASA corpus (levels K-3) and then subset for each program in order to establish a normative distribution as comparison. Word frequencies were arranged in their rank such that a low rank is associated with a high frequency. This preserves an important aspect of the distributional characteristics of frequencies, namely that there are very few high frequency words (those with ranks 1, 2, 3, and so on) and many low frequency words (e.g., many words with a raw frequency of, say, 1; high numerical values for rank).

Words with low age of acquisition are learned earlier in life than those with higher values for age of acquisition (i.e., low value = younger age). Consistency is organized such that numerically low values (e.g., 1, 2, 3, etc.) have low values for consistency (i.e., are inconsistent words with respect to their neighbors based on print-speech mappings). Words with low imageability are less imageable (i.e., tending to be more abstract than high imageability words). Words with few letters and few syllables are short words, though these two variables are less conducive to misinterpretation. Table XX provides a description of what low values on each scale can be interpreted as, and a few examples. Low values are described because words in all distributions in the data described tend to be on the low end of the scale for each variable (and below the mean on the variable in the TASA corpus).


## Results
### General Program Comparisons of Frequency
All instructional resources contain words that are, on average, more frequent (lower standardized rank frequency) than the average word from TASA, as indicated by each mean value for standardized rank frequency being negative. This is expected given than all of the resources are intended to contain common words (based on their own reporting).

These comparisons bear out in a statistical model of each distribution against zero (the normative mean, which is always zero due to standardization). Table XX shows the results from this statistical test for the six resources in the distribution of frequencies in that corpus.

Fry tends to contain the highest frequency words, with the lowest average rank frequency, as well as the least amount of variability. On the other end is Kilpatrick. This set of words is much higher in average rank frequency (i.e., lower in raw frequency) than any of the other resources. The variability in rank frequency for this set is noteworthy as well. Not only are the averages for Kilpatrick much higher in rank frequency than any of the other instructional resources, the spread of frequency values for that source is higher as well. This trend is exhibited in also the extreme values on the low end of frequency for the Kilpatrick set in that the distribution includes words _above the mean_ of words in TASA. It is the only resource that exhibits this property.

Figure XX shows these trends in and across the six lists. The point estimate is shown for each set in each Panel, with standard deviations shown as boxes above and below the estimate in Panel A and standard errors in Panels B and C. The scale in Panel A is such that you can see each list's distribution relative to the mean of TASA (the zero line), shown as a dashed line. Standard deviations are shown in this panel because the small size of the standard errors render them imperceptible at this scale. The data displayed in this way give a sense of the variation within sources especially, given the presence of the raw data points (words). Also, here the differences associate with the Kilpatrick list are quite clear - that resource contains more variable word frequencies and the lowest frequency words are far towards the extreme (i.e., high on the y-axis). Panel B is a zoomed in version of this plot, but showing standard errors from the statistical test of each distribution against zero (the TASA mean). This view permits better comparison across the resources and relative to the mean across all six resources (dotted line). In order to see these data without being obscured by the Kilpatrick set, Panel C shows the same data as in Panel B but only for Dolch, Fountas & Pinnell, Fry, Fundations, and Wonders. This shows the differentiation of Wonders at one end (reliably containing lower frequency words than the other four) and Fry at the other (tending to contain the highest frequency words). Dolch, Fountas & Pinnell, and Wonders exibit comparable distributions for word frequency. See Tables XX and XX for specific quantitative values (descriptive and inferential) to supplement the graphical explanation here.

```{r tasaFreqTtest, echo=FALSE, warning=FALSE, message=FALSE}
z_table_tasa %>% 
  select(-CI_hi, -CI_low, -p_derived, -var) %>%
  apa_table(caption = "Model Outputs by Source for Statistical Test against Mean Rank Frequency from the Educator's Word Frequency Guide (TASA)", note = "Statistical test used was t.test() from base R (R Core Team, 2021). Rank frequencies were Z transformed prior to test, so resulting coefficients express the difference in standard deviations of rank frequency from TASA between the source mean on rank frequency and the TASA mean (0 due to Z transformation).", escape = FALSE)


```



```{r echo=FALSE, message=FALSE, warning=FALSE, fig.cap='In Panel A the raw distribution of words for rank frequency (standardized) from the TASA corpus are shown as points (in grey) with point estimates from the statistical model shown as colored bars. Boxes around the point estimates show standard deviations because standard errors are imperceptibly small. All distributions are significantly different than the corpus mean for TASA (0), which is shown as the dashed line at zero. Panel B shows the same plot but zoomed in so that the differences across resources can be seen, and Panel C shows the same plot but with the Kilpatrick set removed so that the other points (and bars) can be seen more clearly. These panels show standard errors as error bars around the point estimates. In Panels A and B the dotted lines show the mean across the six resources, and in Panel C the dot-dashed line shows the mean for only the five resources shown.', fig.width=7, fig.height=3.5}

# code derivative of this can be used for the supplement because all corpora are included at top level here

VARS = c('tasa_rank', 'wcbc_rank', 'childes_rank', 'coca_rank')


hlines = nsd %>% 
  filter(var %in% VARS) %>% 
  group_by(var) %>% 
  summarise(varmean = mean(M_, na.rm = T)) %>% 
  mutate(var = case_when(var == 'wcbc_rank' ~ 'WCBC',
                         var == 'tasa_rank' ~ 'TASA',
                         var == 'childes_rank' ~ 'CHILDES',
                         var == 'coca_rank' ~ 'COCA')) %>% 
  filter(var == "TASA")

plot_data = Zs %>% 
  filter(var %in% VARS) %>% 
  select(var, source, M = Z) %>% 
  mutate(var = case_when(var == 'wcbc_rank' ~ 'WCBC',
                         var == 'tasa_rank' ~ 'TASA',
                         var == 'childes_rank' ~ 'CHILDES',
                         var == 'coca_rank' ~ 'COCA')) %>% 
  mutate(source_ = fct_relevel(source, 'Kilpatrick', after = 4))

ci_data = z_table_tasa %>% # see frequency_models.R for this object's generation (if rendering to PDF you'll need to change a line there)
  select(source = Source, ci_ = CI95) %>% # you will want to change this line if rendering into PDF
  mutate(ci = str_replace(ci_, "\\[", ""),
         ci = str_replace(ci, "\\]", ""),
         ci_lo = str_split(ci, ",", simplify = T)[,1],
         ci_hi = str_split(ci, ",", simplify = T)[,2],) %>% 
  mutate(ci_lo = as.numeric(ci_lo),
         ci_hi = as.numeric(ci_hi)) %>% 
  select(source, ci_lo, ci_hi)

plot_a = Zs %>% 
  mutate(source_ = fct_relevel(source, 'Kilpatrick', after = 4)) %>% 
  filter(var == "tasa_rank") %>% 
  ggplot(aes(source_, Z, color = source_)) +
  scale_color_manual(values = COLORS_SOURCE) +
geom_point(position = position_jitter(width = .04, height = .01), size = .01, color = 'grey') +
  #geom_point(size = 2) +
  stat_summary(fun.data = "mean_sdl", fun.args = list(mult = 1), geom = "crossbar", width = .2) +
  #geom_errorbar(aes(ymin = ci_lo, ymax = ci_hi, color = source), width = .3) +
  #ylim(c(-2, .5)) +
  labs(x = 'Source', y = 'Rank frequency (Z)') +
  geom_hline(yintercept = 0, linetype = 'dashed', color = 'red') +
  geom_hline(data = hlines, aes(yintercept = varmean), color = 'black', linetype = 'dotted') +
  theme_apa() +
  theme(legend.position = 'none',
        strip.background=element_blank(),
        text = element_text(family = 'Times'),
        axis.text.x = element_text(angle = 60, hjust = 1))

plot_b = Zs %>% 
  group_by(source, var) %>% 
  summarise(M = mean(Z, na.rm = T)) %>% 
  left_join(nsd) %>% 
  filter(var %in% VARS) %>% 
  mutate(var = case_when(var == 'wcbc_rank' ~ 'WCBC',
                         var == 'tasa_rank' ~ 'TASA',
                         var == 'childes_rank' ~ 'CHILDES',
                         var == 'coca_rank' ~ 'COCA'),
                source = as.factor(source)) %>% 
  mutate(source_ = fct_relevel(source, 'Kilpatrick', after = 4)) %>% 
  filter(var == "TASA") %>% 
  left_join(ci_data) %>%
  ggplot(aes(source_, M, color = source_)) +
  scale_color_manual(values = COLORS_SOURCE) +
  geom_point(size = .8) +
  geom_line(color = 'grey') +
  geom_errorbar(aes(ymin = ci_lo, ymax = ci_hi, color = source), width = .35) +
  ylim(c(-1.79, -.5)) +
  labs(x = 'Source', y = 'Rank frequency (Z)') +
  geom_hline(yintercept = 0, linetype = 'dashed', color = 'red') +
  geom_hline(data = hlines, aes(yintercept = varmean), color = 'black', linetype = 'dotted') +
  theme_apa() +
  theme(legend.position = 'none',
        strip.background=element_blank(),
        text = element_text(family = 'Times'),
        axis.text.x = element_text(angle = 60, hjust = 1))


hline_for_set_without_kilpatrick = Zs %>% 
  filter(var == "tasa_rank" & source != "Kilpatrick") %>% 
  summarise(mean = mean(Z, na.rm = T)) %>% 
  pull(mean)

plot_c = Zs %>% 
  group_by(source, var) %>% 
  summarise(M = mean(Z, na.rm = T)) %>% 
  left_join(nsd) %>% 
  filter(var %in% VARS) %>% 
  mutate(var = case_when(var == 'wcbc_rank' ~ 'WCBC',
                         var == 'tasa_rank' ~ 'TASA',
                         var == 'childes_rank' ~ 'CHILDES',
                         var == 'coca_rank' ~ 'COCA'),
                source = as.factor(source)) %>% 
  mutate(source_ = fct_relevel(source, 'Kilpatrick', after = 4)) %>% 
  filter(var == "TASA") %>% 
  filter(source_ != "Kilpatrick") %>% 
  left_join(ci_data) %>%
  ggplot(aes(source_, M, color = source_)) +
  scale_color_manual(values = COLORS_SOURCE) +
  geom_point(size = 1) +
  geom_line(color = 'grey') +
  geom_errorbar(aes(ymin = ci_lo, ymax = ci_hi, color = source), width = .35) +
  ylim(c(-1.70, -1.60)) +
  labs(x = 'Source', y = 'Rank frequency (Z)') +
  geom_hline(yintercept = hline_for_set_without_kilpatrick, color = 'grey37', linetype = 'dotdash') +
  theme_apa() +
  theme(legend.position = 'none',
        strip.background=element_blank(),
        text = element_text(family = 'Times'),
        axis.text.x = element_text(angle = 60, hjust = 1)) +
  scale_y_continuous(labels = round_axis_text)

plot_grid(plot_a, plot_b, plot_c, ncol = 3, nrow = 1, align = "v", labels = c("A", "B", "C"))
```

### Coverage of Most Frequent Words
We could reasonably expect that these resources draw from the most frequent words in child-directed print. One way of examining this is calculating the proportion of the most frequent *n* words in TASA that a given resource contains. Given that this corpus represents a relevant learning environment for an early reader, each instructional set should contain a nontrivial proportion of the most frequent words in the corpus. We've calculated these distributions here (shown in Table XX) using the most frequent 50, 100, 500, and 1000 words. Table XX shows the most frequent 50 words in TASA for reference.

```{r coverageKidCorpus, echo=FALSE, warning=FALSE, message=FALSE}
ROWS = length(unique(all_lists$source))*length(unique(top_N$corpus))*length(unique(top_N$top_n))
COLS = c("source", "corpus", "top_n", "in_program", "proportion")


coverage = data.frame(matrix(nrow = ROWS, ncol = length(COLS)))
colnames(coverage) = COLS

i = 1

for (source_ in unique(all_lists$source)){
  
  trigger = all_lists %>% 
        filter(source == source_) %>% 
        distinct(word) %>% 
        pull(word)
  
  for (corpus_ in unique(top_N$corpus)){
    for (N in unique(top_N$top_n)){
      
      # get all the words for a given source (program)
      
      
      # get all the words from a given corpus as a specific level of "top N" (i.e. 100, 500, 1000)
      target = top_N %>% 
        filter(corpus == corpus_) %>% 
        filter(top_n == N) %>% 
        pull(word)

      coverage$source[i] = source_
      coverage$corpus[i] = corpus_
      coverage$top_n[i] = as.numeric(N)
      coverage$in_program[i] = length(intersect(target, trigger))
      coverage$proportion[i] = length(intersect(target, trigger))/as.numeric(N)
      
      i = i + 1
      
    }}}


```



```{r}
top_N %>% 
  filter(top_n == 50 & corpus == "tasa") %>% 
  mutate(word = case_when(word == "i" ~ toupper(word),
                          TRUE ~ word)) %>% 
  pull(word) %>% 
  matrix(nrow = 10) %>% 
  data.frame() %>% 
  apa_table(col.names = c("", "", "", "", ""),
            caption = "The Top 50 Words by Frequency from the Educator's Word Frequency Guide (TASA).",
            note = 'The highest-rank word by frequency is shown in the top left ("the"), and words increase in rank top to bottom left to right')

```

The trends for all six programs follow a common pattern. Programs tend to exhibit more coverage for the most frequent 50 and 100 words, less so for the most frequent 500 and even less for the most frequent 1000. This general fact is not surprising. However, the resources vary in this coverage trend.

Wonders contains the most words, with 801, so it is perhaps unsurprising that its coverage is greatest. With this quantity of words, it stands out that it only contains 65% of the most frequent 500 words from TASA. That list is the only one with enough to potentially contain 100% of those words (which it does not). By contrast, the Dolch and Fry words obtain comparable coverage with fewer words, each with less than half of that than Wonders. Nonetheless, Wonders, Fry, and Dolch demonstrate very similar levels of coverage. All three have greater than 75% coverage for TASA on the top 50 and top 100 words and around half of the top 500 words. Fountas and Pinnell exhibit slightly lower levels of coverage than those three, with Fundations demonstrating even less coverage than Fountas and Pinnell. The coverage for Kilpatrick is very low, even for the most frequent 50 words. This is fact can be emphasized given that Kilpatrick contains the second most number of words behind Wonders, and over 100 words more than the Dolch list.

<!-- ```{r coverageKidCorpusTable, echo=FALSE, warning=FALSE, message=FALSE} -->
<!-- coverage %>%  -->
<!--   select(-in_program) %>%  -->
<!--   mutate(proportion = round(proportion, digits = 2)) %>%  -->
<!--   pivot_wider(names_from = top_n, values_from = proportion) %>%  -->
<!--   filter(corpus == "tasa") %>%  -->
<!--   select(-corpus) %>%  -->
<!--   left_join(coverage %>%  -->
<!--               group_by(source) %>%  -->
<!--               summarise(proportion_ = mean(proportion)) %>%  -->
<!--               arrange(desc(proportion_)) %>%  -->
<!--               mutate(order = seq_len(n()))) %>%  -->
<!--   arrange(order) %>%  -->
<!--   mutate(source = case_when(source == 'dolch' ~ 'Dolch', -->
<!--                             source == 'fry' ~ 'Fry', -->
<!--                             source == 'fundations' ~ 'Fundations', -->
<!--                             source == 'kilpatrick' ~ 'Kilpatrick', -->
<!--                             source == 'wonders' ~ 'Wonders', -->
<!--                             source == 'fountas_pinnell' ~ 'F&P')) %>%  -->
<!--   left_join(all_lists %>%  -->
<!--               group_by(source) %>%  -->
<!--               summarise(n_ = n()) %>%  -->
<!--               mutate(source = case_when(source == 'dolch' ~ 'Dolch', -->
<!--                             source == 'fry' ~ 'Fry', -->
<!--                             source == 'fundations' ~ 'Fundations', -->
<!--                             source == 'kilpatrick' ~ 'Kilpatrick', -->
<!--                             source == 'wonders' ~ 'Wonders', -->
<!--                             source == 'fountas_pinnell' ~ 'F&P'))) %>%  -->
<!--   mutate(source = str_c(source, " (", n_, ")")) %>%              -->
<!--   select(`Resource (N)` = source, `50`, `100`, `500`, `1000`) %>%  -->
<!--   apa_table(caption = "Proportion Coverage of Top 50, 100, 500, and 1000 Words from TASA for the Six Resources.", -->
<!--             note = "Number of words in each resource is provided next to the name of the resource for reference.", -->
<!--             col_spanners = list("Top N" = c(2, 5))) -->

<!-- ``` -->

```{r coverageKidCorpusFigure, echo=FALSE, warning=FALSE, message=FALSE, fig.cap="Coverage for each program (panel) for each level of most frequent 50, 100, 500, and 1000 words for TASA. Programs exhibit variable coverage at each level for the corpus, with Wonders, Fry, and Dolch showing comparable levels of coverage at one extreme, and Kilpatrick at the other.", fig.width=7}

coverage %>%
  filter(corpus == "tasa") %>% 
  mutate(source = case_when(source == 'dolch' ~ 'Dolch',
                            source == 'fry' ~ 'Fry',
                            source == 'fundations' ~ 'Fundations',
                            source == 'kilpatrick' ~ 'Kilpatrick',
                            source == 'wonders' ~ 'Wonders',
                            source == 'fountas_pinnell' ~ 'F&P')) %>% 
  ggplot(aes(as.factor(top_n), proportion, fill = as.factor(top_n))) +
  geom_bar(stat = "identity", position = "dodge", color = "black") +
  #geom_text(aes(label = sub("^0\\.", ".", round(proportion, digits = 2))), size = 2.5, vjust = 1.8, alpha = .8) +
  facet_grid(~factor(source, levels = c("Dolch",  "Fry", "F&P", "Fundations", "Wonders", "Kilpatrick"))) + # change order here
  theme_apa() +
  labs(x = "N most frequent", y = "Proportion covered", fill = "N most frequent") +
  theme(text = element_text(family = "Times"),
        axis.text.x = element_text(angle = 90, vjust = .5, hjust = 1),
        legend.position = "none") +
  scale_fill_manual(values = c("burlywood", "gold2", "brown", "darkorchid4"))
```

### General Comparison of Resources based on Other Word Characteristics
The resources always land below the mean on the standardized rank scale of each variable (below the dashed line; see below for more dicsussion of the the Dolch set with regards to consistency). All resources contain words that are learned earlier than the average word in TASA (lower in rank AoA), are less consistent (lower rank consistency; except for Dolch), are less imageable (lower rank imageability), have fewer letters (lower rank letters), and fewer syllables (lower rank syllables). Additionally, each resource rarely falls on the mean for all resources (i.e., has a bar that falls on the dotted line), which suggests noteworthy variability across resources.

Fundations, Kilpatrick, and Dolch are, in general, associated with more extreme positions relative to the group mean across each of the variables - though in different directions. Fundations favors words with lower age-of-acquisition, lower consistency, lower imageability, and more syllables than the rest. Kilpatrick tends towards words with higher AoA (learned later) and more letters. Dolch contain words that are more consistent and more imageable, though shorter (in terms of letters and syllables). Fry, Fountas and Pinnell, and Wonders tend to be more moderate than the others, exhibiting more instances where their distribution straddles the mean for all resources (and each showing no instance of being the extreme value on any given variable).

```{r profileFigureLexical, echo=FALSE, message=FALSE, warning=FALSE, fig.cap='Means and standard errors for a range of word variables within sources are shown. Means are calculated over standardized measures within TASA, therefore the position of the point for a source for a variable can be interpreted as the average distance away from the mean of all words within TASA (i.e., 0 shown with a red dashed line) for that variable in terms of standard deviation units. The mean on a given variable across all sources is shown as a grey dotted line just for convenience. Estimates were derived using t.test() in base R.', fig.width=7}
VARS = c('consistency', 'aoa', 'letters', 'syllables', 'imageability')

bardata = z_tables_lexical %>% 
  select(source = Source, se = `\\textit{SE}`, var, M = `\\textit{b}`) %>% 
  mutate(se = as.numeric(se),
         M = latex_to_num(M)) %>% 
  mutate(var = case_when(var == 'consistency' ~ 'Consistency',
                         var == 'syllables' ~ 'Syllables',
                         var == 'aoa' ~ 'AoA',
                         var == 'imageability' ~ 'Imageability',
                         var == 'letters' ~ 'Letters')) 
  
hlines = nsd %>% 
  filter(var %in% VARS) %>% 
  group_by(var) %>% 
  summarise(sourcemean = mean(M_, na.rm = T)) %>% 
  mutate(var = case_when(var == 'consistency' ~ 'Consistency',
                         var == 'syllables' ~ 'Syllables',
                         var == 'aoa' ~ 'AoA',
                         var == 'imageability' ~ 'Imageability',
                         var == 'letters' ~ 'Letters')) 

Zs %>% 
  group_by(source, var) %>% 
  summarise(source_order = first(source_order)) %>% 
  filter(var %in% VARS) %>% 
  mutate(var = case_when(var == 'consistency' ~ 'Consistency',
                         var == 'syllables' ~ 'Syllables',
                         var == 'aoa' ~ 'AoA',
                         var == 'imageability' ~ 'Imageability',
                         var == 'letters' ~ 'Letters')) %>% 
  left_join(bardata) %>% 
  ggplot(aes(reorder(source, source_order), M, color = reorder(source, source_order), group = reorder(var, source_order))) +
  geom_hline(data = hlines, aes(yintercept = sourcemean), color = 'black', linetype = 'dotted') +
  scale_color_manual(values = COLORS_SOURCE) +
  geom_point(size = 2) +
  geom_line(color = 'grey') +
  geom_errorbar(aes(ymin = M-se, ymax = M+se), size = .5, width = .8) +
  labs(color = 'Source', x = 'Variable', y = 'Standardized value (within TASA)') +
  facet_grid(~var)  +
  geom_hline(yintercept = 0, linetype = 'dashed', color = 'red') +
  theme_apa() +
  theme(legend.position = 'top',
        axis.ticks.x = element_blank(), 
        axis.text.x = element_blank(),
        text = element_text(family = 'Times'))

```

Except for the Dolch word's distribution for consistency, differences between the source distribution on each word-level variable relative to the normative distribution (TASA) are all statistically significant based on a statistical test of the mean against zero (paralleling the tests conducted previously on the frequency distributions).

```{r profileTableStatTest, echo=FALSE, message=FALSE, warning=FALSE}
Source = z_tables_lexical %>% filter(var == 'aoa') %>% pull(Source)
AoA = z_tables_lexical %>% filter(var == 'aoa') %>% rename(b = `\\textit{b}`, se = `\\textit{SE}`) %>% mutate(o = paste(b, ' (', se, ')', sep = '')) %>%  pull(o)
Consistency = z_tables_lexical %>% filter(var == 'consistency') %>% rename(b = `\\textit{b}`, se = `\\textit{SE}`) %>% mutate(o = paste(b, ' (', se, ')', sep = '')) %>%  pull(o)
Imageability = z_tables_lexical %>% filter(var == 'imageability') %>% rename(b = `\\textit{b}`, se = `\\textit{SE}`) %>% mutate(o = paste(b, ' (', se, ')', sep = '')) %>%  pull(o)
Letters = z_tables_lexical %>% filter(var == 'letters') %>% rename(b = `\\textit{b}`, se = `\\textit{SE}`) %>% mutate(o = paste(b, ' (', se, ')', sep = '')) %>%  pull(o)
Syllables = z_tables_lexical %>% filter(var == 'syllables') %>% rename(b = `\\textit{b}`, se = `\\textit{SE}`) %>% mutate(o = paste(b, ' (', se, ')', sep = '')) %>%  pull(o)

data.frame(cbind(Source, AoA, Consistency, Imageability, Letters, Syllables)) %>% 
  mutate(Source = case_when(Source == 'Dolch' ~ 'Dolch',
                            Source == 'Fry' ~ 'Fry',
                            Source == 'Fundations' ~ 'Fundations',
                            Source == 'Kilpatrick' ~ 'Kilpatrick',
                            Source == 'Wonders' ~ 'Wonders',
                            Source == 'Fountas_pinnell' ~ 'Fountas & Pinnell')) %>%
  apa_table(caption = 'Model Estimates for Statistical Tests of Source Means against Means from Normative Sample', 
            note = 'Estimates obtained from using t.test() from base R, with standard errors in parentheses. Bolded parameter estimates are statistically significant. For a full accounting of parameter estimates see appendix. Values were Z transformed on the distribution from the TASA prior to subsetting and testing by source.', escape = FALSE)
  
```

## Discussion
Words are known to vary in terms of a number of properties that contribute to learning to read [@Zevin2002; @Zevin2004; @Hsiao2018; @Weekes2006]. While we've demonstrated that the instructional resources studied here vary in terms of the specific words they contain, it could be that their words possess equivalent (or comparable) underlying properties. That is, two lists might contain different words but the words might be matched in terms of their frequency, age of acquisition, consistency, and other variables known to be relevant to learning. If this were the case, the differences in the words selected for a given resource would be less meaningful; instruction in any particular program would be associated with delivering similar properties of the language despite differences in the individual words. This turns out not to be the case, however. Noteworthy variability exists across the instructional wordlists along all variables studied here: frequency, consistency, imageability, age-of-acquisition, number of letters, and number of syllables. These differences can be understood in terms of variation relative to each other or variation relative to a normative sample (here the words from TASA, grades K-3 were used) - each provides a meaningful perspective on the variation in programs and their potential impact on child reading development.

### Properties of Words in Programs: Variation Relative to Each Other
In many cases the programs differentiate in terms of the distribution of their properties relative to other programs. For word frequency, Fry, Fundations, and Kilpatrick exhibit this trend. Kilpatrick's words, as is generally the case across analyses here, represent one extreme - tending to contain words that are very low frequency relative to the others. Fundations contains relatively low frequency words as well. That set is above the mean of frequency when looking only at the Dolch, Fountas & Pinnell, Fry, Fundations, and Wonders sets (see Figure XX, Panel C), though is still well below the mean rank frequency in TASA. On the other extreme is Fry, which tends to contain words that are the highest frequency (lowest in rank frequency).

Variation across resources exists, and in many cases is more dramatic, when examining properties other than frequency. In the distribution of consistency values, for example, the resources split into two different subgroups: those that contain words that are below the mean for the six resources (Fundations, Wonders, Kilpatrick) and those that are above that mean (Dolch, Fry, and Fountas & Pinnell). Fundations and Kilpatrick are most clearly differentiated on their extreme. These two programs contain words that are much more inconsistent than the others. This tendency fits with the characterization of the Fundations and Kilpatrick programs, whose instruction tends to focus on idiosyncratic print structure of words in English. Interestingly, Fundations targets words that are both irregular and frequent, where Kilpatrick's explanation focuses on the irregularity of the words selected (see Methods section on this program for further description). Nonetheless, Fundations contains words that tend to be more inconsistent than those in Kilpatrick.

Fundations and Kilpatrick also occupy outlier positions for age of acquisition, though in this case they are on opposite ends: Fundations contains words that are on average the lowest AOA words, and Kilpatrick contains the highest AOA words. The other four programs cluster together, right around the average value for AOA for the six resources. Note that for Fundations, this tendency to contain words that are low in age of acquisition but contain inconsistent print-speech structure characterizes the potential learnability of that program's words. Their words, while idiosyncratic from the perspective of print and speech are more likely to be words that the child already knows from spoken language. By contrast, Kilpatrick's words are both inconsistent and are higher in age of acquisition. This will cause words in that set to be more difficult to learn. The words will have fewer neighbors and less likely to be known from speech by the child. This tendency is compounded by their relative infrequency, as described above.



### Properties of Words in Programs: Variation Relative to a Normative Sample
Relative to TASA, all resources contain words more frequent than the average frequency from that corpus. However, Kilpatrick's set contains words that are at or above the mean frequency from TASA, a trend that differentiates this program from the rest. Kilpatrick's resource aside, all other resources do in fact contain "high frequency" words when comparing against this normative distribution. This is good and expected given that they advertise themselves as such. Nonetheless, the extent to which they do so varies quantitatively. These trends are recapitulated when we examine the coverage of the most frequent words in TASA (e.g., Figure XX), though the relative distributions of each program when examining the data in this way shifts a bit. Here, Wonders, Fry, and Dolch do very well in their coverage of the top 50 and top 100 words from TASA: they contain almost every one of these words. Wonders contains the best coverage of the top 500 and 1000 words from TASA (.65 and .41 of these words, respectively). Analagous to the comparison of average frequency relative to the mean TASA frequency, Fundations and Kilpatrick do least well in coverage of the top 50, 100, 500, and 1000 words. These resources contain only .16 (Fundations) and .1 (Kilpatrick) of the most frequent 1000 words from TASA, which is much lower than the .41 contained by Wonders. It important to keep in mind that Wonders contains the most words in general, with 801, which is close to twice as many words as the next largest program (Fountas & Pinnell, 443 words).

